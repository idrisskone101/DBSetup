import "dotenv/config.js";
import { supabase } from "./supabase-upsert.js";
import {
  generateVibeEmbeddings,
  generateContentEmbeddings,
  generateMetadataEmbeddings,
} from "./embeddings.js";

const FETCH_CHUNK_SIZE = 50; // Fetch 50 titles at a time from database (avoids timeout)

/**
 * Backfill all 3 embeddings (vibe, content, metadata) for titles missing any embedding
 * Uses CHUNKED database fetching to avoid statement timeout errors
 * Processes in small batches to stay under the 2-minute database timeout
 */
async function backfillMissingEmbeddingsChunked() {
  console.log("ğŸš€ Starting CHUNKED incremental multi-embeddings backfill...\n");
  console.log("ğŸ“Š This will fetch titles in small chunks to avoid database timeouts\n");

  try {
    // First, get a count of how many titles need embeddings
    console.log("ğŸ“Š Counting titles with missing embeddings...");
    const { count: totalMissing, error: countError } = await supabase
      .from("titles")
      .select("*", { count: "exact", head: true })
      .or("vibe_embedding.is.null,content_embedding.is.null,metadata_embedding.is.null");

    if (countError) {
      throw new Error(`Failed to count titles: ${countError.message}`);
    }

    if (totalMissing === 0) {
      console.log("âœ… All titles have all 3 embeddings! Nothing to do.");
      return;
    }

    console.log(`ğŸ“ Found ${totalMissing} title(s) with missing embeddings\n`);
    console.log(`ğŸ’° Estimated cost: ~$${((totalMissing * 3 * 0.00013) / 10).toFixed(4)} USD\n`);

    let totalProcessed = 0;
    let successCount = 0;
    let failedCount = 0;
    const failedTitles = [];

    let offset = 0;
    let hasMore = true;
    let chunkNumber = 1;

    // Process titles in chunks to avoid database timeout
    while (hasMore) {
      console.log(`\n${"â”".repeat(60)}`);
      console.log(`ğŸ“¦ Fetching chunk ${chunkNumber} (offset: ${offset}, limit: ${FETCH_CHUNK_SIZE})...`);
      console.log("â”".repeat(60));

      // Fetch a small chunk of titles with missing embeddings
      const { data: titles, error } = await supabase
        .from("titles")
        .select("*")
        .or("vibe_embedding.is.null,content_embedding.is.null,metadata_embedding.is.null")
        .order("id")
        .range(offset, offset + FETCH_CHUNK_SIZE - 1);

      if (error) {
        console.error(`âŒ Error fetching chunk ${chunkNumber}:`, error.message);
        // Don't throw - try to continue with next chunk
        offset += FETCH_CHUNK_SIZE;
        chunkNumber++;
        hasMore = offset < totalMissing;
        continue;
      }

      if (!titles || titles.length === 0) {
        console.log("âœ… No more titles to process");
        hasMore = false;
        break;
      }

      console.log(`âœ… Fetched ${titles.length} title(s) in chunk ${chunkNumber}`);

      // Show what's missing in this chunk
      const missingVibe = titles.filter((t) => !t.vibe_embedding).length;
      const missingContent = titles.filter((t) => !t.content_embedding).length;
      const missingMetadata = titles.filter((t) => !t.metadata_embedding).length;

      console.log(`ğŸ“Š Missing in this chunk:`);
      console.log(`   ğŸ­ Vibe: ${missingVibe}`);
      console.log(`   ğŸ“– Content: ${missingContent}`);
      console.log(`   ğŸ·ï¸  Metadata: ${missingMetadata}`);

      try {
        // Generate all 3 embedding types for this chunk
        console.log(`\nğŸ”„ Generating embeddings for chunk ${chunkNumber}...`);
        const [vibeEmbeddings, contentEmbeddings, metadataEmbeddings] =
          await Promise.all([
            generateVibeEmbeddings(titles),
            generateContentEmbeddings(titles),
            generateMetadataEmbeddings(titles),
          ]);

        console.log("ğŸ’¾ Updating database...");

        // Update each title individually with all 3 embeddings
        let updateCount = 0;
        for (let i = 0; i < titles.length; i++) {
          const title = titles[i];
          const vibeEmbedding = vibeEmbeddings[i];
          const contentEmbedding = contentEmbeddings[i];
          const metadataEmbedding = metadataEmbeddings[i];

          // Skip if any embedding generation failed
          if (
            vibeEmbedding === null ||
            contentEmbedding === null ||
            metadataEmbedding === null
          ) {
            console.warn(
              `âš ï¸  Skipping title ${title.id} (${title.title}) - embedding generation failed`,
            );
            failedTitles.push({ id: title.id, title: title.title });
            failedCount++;
            continue;
          }

          // Update all 3 embeddings at once
          const { error: updateError } = await supabase
            .from("titles")
            .update({
              vibe_embedding: vibeEmbedding,
              content_embedding: contentEmbedding,
              metadata_embedding: metadataEmbedding,
              updated_at: new Date().toISOString(),
            })
            .eq("id", title.id);

          if (updateError) {
            console.error(
              `âŒ Failed to update title ${title.id} (${title.title}): ${updateError.message}`,
            );
            failedTitles.push({ id: title.id, title: title.title });
            failedCount++;
            continue;
          }

          updateCount++;
        }

        if (updateCount > 0) {
          successCount += updateCount;
          console.log(`âœ… Successfully updated ${updateCount} title(s) with all 3 embeddings`);
        }

        const failedInChunk = titles.length - updateCount;
        if (failedInChunk > 0) {
          console.warn(`âš ï¸  Failed to update ${failedInChunk} title(s) in this chunk`);
        }

        totalProcessed += titles.length;

        // Progress update
        const progressPct = Math.round((totalProcessed / totalMissing) * 100);
        console.log(
          `ğŸ“ˆ Overall Progress: ${totalProcessed}/${totalMissing} (${progressPct}%)`,
        );

        // Small delay between chunks to avoid rate limiting
        console.log("â³ Waiting 2 seconds before next chunk...");
        await new Promise((resolve) => setTimeout(resolve, 2000));
      } catch (error) {
        console.error(`âŒ Error processing chunk ${chunkNumber}:`, error.message);

        // Mark all titles in this chunk as failed
        titles.forEach((title) => {
          failedTitles.push({ id: title.id, title: title.title });
        });
        failedCount += titles.length;
        totalProcessed += titles.length;
      }

      // Move to next chunk
      offset += FETCH_CHUNK_SIZE;
      chunkNumber++;

      // Check if there are more titles to fetch
      hasMore = titles.length === FETCH_CHUNK_SIZE && totalProcessed < totalMissing;
    }

    // Final summary
    console.log("\n" + "â”".repeat(60));
    console.log("âœ¨ CHUNKED INCREMENTAL BACKFILL COMPLETE");
    console.log("â”".repeat(60));
    console.log(`ğŸ“Š Total titles processed: ${totalProcessed}`);
    console.log(`âœ… Successfully generated embeddings: ${successCount}`);
    console.log(`âš ï¸  Failed to generate embeddings: ${failedCount}`);
    console.log(`ğŸ’¾ Database now has 3 embedding types per title:`);
    console.log(`   ğŸ­ vibe_embedding`);
    console.log(`   ğŸ“– content_embedding`);
    console.log(`   ğŸ·ï¸  metadata_embedding`);

    if (failedTitles.length > 0) {
      console.log(`\nâš ï¸  Failed titles (${failedTitles.length}):`);
      failedTitles.slice(0, 10).forEach((t) => {
        console.log(`   - ${t.id}: ${t.title}`);
      });
      if (failedTitles.length > 10) {
        console.log(`   ... and ${failedTitles.length - 10} more`);
      }
    }

    console.log("â”".repeat(60) + "\n");
  } catch (error) {
    console.error("\nâŒ Fatal error during chunked backfill:", error);
    process.exit(1);
  }
}

// Main execution
backfillMissingEmbeddingsChunked().catch((e) => {
  console.error(e);
  process.exit(1);
});
